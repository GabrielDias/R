---
title: "Vinhos"
author: "Gabriel Dias - RM330587, Guilherme Lahr - RM330351"
date: "`r format(Sys.Date())`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

##Importação de bibliotecas e configurações

```{r warning=FALSE, message=FALSE}
library("psych")
library("plotly")
library("gmodels")
library("corrgram")
library("corrplot")
library("rpart")
library("rpart.plot")
library("dplyr")
# mostrar até 2 casas decimais
options("scipen" = 2)

#leitura csv
#Vinhos <- read.csv2("C:/Users/Gabriel.Dias/Desktop/R/estatistica/BaseWine_Red_e_White2018.csv", row.names=1)
Vinhos <- read.csv2("D:/R/Vinhos dataset/BaseWine_Red_e_White2018.csv", row.names=1)
```
*****
##Análise exploratória de dados
*****
Para começar a exploração dos dados da base de vinhos será executado comandos que exibem as variáveis existentes dentro do dataset, seus respectivos tipos e os primeiros registros:

```{r warning=FALSE, message=FALSE}
#mostrar as variáveis
str(Vinhos)
#mostra as variáveis
names(Vinhos)
```


Na amostra que temos vamos analisar a qualidade por tipo de vinho realizando o cálculo de distruibuição de frequência absoluta:

```{r warning=FALSE, message=FALSE}
# Frequência absoluta 
#os 2 comandos dao o mesmo resultado porque nao ha nulos no campo qualidade
#table(as.factor(Vinhos$quality), Vinhos$Vinho, useNA = "ifany")

table(as.factor(Vinhos$quality), Vinhos$Vinho)

#outra visualização, comparando distribuição dos dados por nota e tipo de vinho
CrossTable(as.factor(Vinhos$quality), Vinhos$Vinho) 
```

Temos 4898 observações de vinho branco e 1599 de vinho tinto. Por enquanto pode-se observar que da amostra o vinho tinto nunca teve nota 9 e que a maior parte das notas atribuidas foram 5 e 6 (para ambos os vinhos). Abaixo vamos analisar um sumário de cada variável do dataset (min, max, mediana, média, $1^o$ e $3^o$ quartis)
```{r warning=FALSE, message=FALSE, echo=FALSE}
summary(Vinhos)

attach(Vinhos)
par (mfrow=c(3,4))
hist(fixedacidity)
hist(volatileacidity)
hist(citricacid )
hist(residualsugar)
hist(chlorides)
hist(freesulfurdioxide)
hist(totalsulfurdioxide)
hist(density)
hist(pH)
hist(sulphates)
hist(alcohol)
hist(quality)
```

Embora nos dê uma boa visão de distribuição dos dados, os histogramas acima podem dificultar a análise em cima de vinhos tinto e branco individualmente. O problema da sumarização acima é que os cálculos são feitos na base inteira, podendo mascarar outliers, por exemplo. Ou então a média ficar muito abaixo/acima do esperado por vinho (vimos anteriormente que a proporção de dados vinho tinto/branco não é equilibrada, é 3 para 1 praticamente). 

Com o uso da função agreggate essa divisão por tipo de vinho será possível.

```{r warning=FALSE, message=FALSE}
#mediana
aggregate(Vinhos[,-13], #remover o tipo de vinho, qualitativo
          by = list(Vinhos$Vinho),
          FUN = median)

```

Pela mediana, é possível perceber diferenças principalmente nas variáveis que estão associados ao dióxido de enxofre, principalmente a *totalsulfurdioxide*. O vinho tinto deveria ter menos açúcar que o branco também, pode-se fazer uma análise com essas variáveis para ver a distribuição dos dados.

```{r warning=FALSE, message=FALSE}
boxplot(totalsulfurdioxide ~ Vinho, main='totalsulfurdioxide')
boxplot(freesulfurdioxide ~ Vinho, main='freesulfurdioxide')
boxplot(residualsugar ~ Vinho, main='residualsugar')
```

*****
## Remoção de outliers
*****
Dado a distribuição de tipos de vinhos, vamos trabalhar apenas com o vinho branco.

```{r warning=FALSE, message=FALSE}
branco <- subset(Vinhos, Vinho=="WHITE", select=c(quality,fixedacidity,volatileacidity,citricacid,residualsugar,
                                                 chlorides,freesulfurdioxide,totalsulfurdioxide,density,pH,
                                                 sulphates,alcohol))
par(mfrow=c(3,4))
for(i in names(branco)){
  if(i!='quality'){
    plot(branco$quality,branco[[i]],xlab="qualidade",ylab=i)
  }
}

summary(branco)

rm(i)

par(mfrow=c(1,1))

cor_branco <- cor(branco, method = "pearson")
corrplot(cor_branco, type = 'upper', method = 'number',number.cex=0.7)
```

Analisando a tabela acima de correlação é possível ver que a variável quality tem correlação mais alta com a variável álcool (porém com um índice relativamente médio - 0.44). É possível analisar também que residualsugar e density possuem alta correlação (0.84). Para remoção dos outliers, calcular diferença interquartílica.

```{r warning=FALSE, message=FALSE}
#calculo da diferenca interquartilica, AIQ
#açucar
AIQ_residualsugar<-quantile(branco$residualsugar,.75,type=2)-quantile(branco$residualsugar,.25,type=2)
limsup_residualsugar= quantile(branco$residualsugar,.75,type=2)+1.5*AIQ_residualsugar
liminf_residualsugar= quantile(branco$residualsugar,.25,type=2)-1.5*AIQ_residualsugar
branco <- subset(branco, residualsugar >= liminf_residualsugar & residualsugar <= limsup_residualsugar)

rm(AIQ_residualsugar)
rm(limsup_residualsugar)
rm(liminf_residualsugar)

#par (mfrow=c(1,2))
attach(branco)
boxplot(residualsugar, main='residualsugar - branco')

#totalsulfurdioxide
AIQ_totalsulfurdioxide<-quantile(branco$totalsulfurdioxide,.75,type=2)-quantile(branco$totalsulfurdioxide,.25,type=2)
limsup_totalsulfurdioxide = quantile(branco$totalsulfurdioxide,.75,type=2)+1.5*AIQ_totalsulfurdioxide
liminf_totalsulfurdioxide = quantile(branco$totalsulfurdioxide,.25,type=2)-1.5*AIQ_totalsulfurdioxide
branco <- subset(branco, totalsulfurdioxide >= liminf_totalsulfurdioxide & totalsulfurdioxide <= limsup_totalsulfurdioxide)

rm(AIQ_totalsulfurdioxide)
rm(limsup_totalsulfurdioxide)
rm(liminf_totalsulfurdioxide)

#par (mfrow=c(1,2))
attach(branco)
boxplot(totalsulfurdioxide, main='totalsulfurdioxide - branco')

#freesulfurdioxide
AIQ_freesulfurdioxide<-quantile(branco$freesulfurdioxide,.75,type=2)-quantile(branco$freesulfurdioxide,.25,type=2)
limsup_freesulfurdioxide= quantile(branco$freesulfurdioxide,.75,type=2)+1.5*AIQ_freesulfurdioxide
liminf_freesulfurdioxide= quantile(branco$freesulfurdioxide,.25,type=2)-1.5*AIQ_freesulfurdioxide
branco <- subset(branco, freesulfurdioxide >= liminf_freesulfurdioxide & freesulfurdioxide <= limsup_freesulfurdioxide)

rm(AIQ_freesulfurdioxide)
rm(limsup_freesulfurdioxide)
rm(liminf_freesulfurdioxide)

#par (mfrow=c(1,2))
attach(branco)
boxplot(freesulfurdioxide, main='freesulfurdioxide - branco')

par(mfrow=c(1,1))

cor_branco <- cor(branco, method = "pearson")
corrplot(cor_branco, type = 'upper', method = 'number',number.cex=0.7)

#dataset teste e treino
set.seed(20)
treino <- sample(1:NROW(branco), as.integer(2/3*NROW(branco)))

trainData <- branco[treino,]
testData  <- branco[-treino,]

prop.table(table(trainData$quality))
prop.table(table(testData$quality))

```

Mesmo com a remoção dos outliers, a matriz de correlação ficou muito parecida com a anterior.  

*****
## Regressão linear
*****
Para todas os modelos que serão apresentados a partir de agora, estaremos tentando calcular a variável dependente 'quality' em função das outras variáveis (independentes) presentes no dataset.  

Para iniciar os modelos, o primeiro a ser utilizado será a regressão linear, que basicamente é uma equação que visa estimar a condicional de quality em função das outras variáveis.  

Dado a matriz de correlação anterior, espera-se que a variável álcool seja mais relevante para montar a função. Desconsideramos a variável densidade devido seu correlacionamento negativo com álcool.
```{r warning=FALSE, message=FALSE}

attach(trainData)
set.seed(20)
ajuste_branco <- lm(quality ~ freesulfurdioxide + totalsulfurdioxide + residualsugar + fixedacidity + volatileacidity
                   + citricacid + chlorides + pH + sulphates + alcohol)

summary(ajuste_branco)
```

Com as variáveis selecionadas, verificamos que existem alguns p-values altos e R quadrado muito ruim. Vamos rodar um novo modelo removendo essas variáveis com p-value alto e ver como fica o resultado.

```{r}
attach(trainData)
set.seed(20)
ajuste_branco <- lm(quality ~ freesulfurdioxide  + residualsugar + volatileacidity + sulphates + alcohol)

summary(ajuste_branco)

set.seed(20)
pred_rl <- predict(ajuste_branco,interval = "prediction", level = 0.95) 

yprob <- predict(ajuste_branco,testData)
hist(yprob)

testData$rl <- yprob

head(select(testData, quality, rl), n = 20)

par(mfrow=c(1,2))
plot(testData$quality,testData$alcohol,xlab="qualidade",ylab="álcool")
plot(testData$rl,testData$alcohol,xlab="qualidade",ylab="álcool")
```

Mesmo com a remoção de algumas variáveis, os valores não mudaram muito - principalmente do R quadrado. Aplicando o modelo no set de teste, percebe-se que o modelo prediz relativamente bem a maior parte das observações, quando elas não são nota 3 ou acima de 8 (poucas observações nesses casos ou então não foi possível encontrar um padrão para notas muito boa ou muito ruins). 

*****
## Árvore de regressão
*****
Diferente da regressão linear, as árvores utilizam todas as variáveis independentes para ela mesmo escolher quais são mais relevantes para predição/classificação. A árvore de regressão devolve uma resposta númerica ou contínua - nesse ponto será muito parecido com a regressão linear, onde temos notas quebradas. 

```{r warning=FALSE, message=FALSE}
set.seed(20)
arvore_br <- rpart(quality ~ freesulfurdioxide + totalsulfurdioxide + 
    residualsugar + fixedacidity + volatileacidity + citricacid + 
    chlorides + density + pH + sulphates + alcohol, data = trainData)

summary(arvore_br)

rpart.plot(arvore_br)

pred_arreg <- predict(arvore_br, newdata = testData)
testData$arvReg <- pred_arreg

head(select(testData, quality, rl, arvReg), n = 30)
```

Quando comparado qualidade com resultado da regressão e resultado da árvore de regressão atual, vemos que na maior parte das vezes a regressão estava mais próxima. Interessante observar as variáveis que a árvore considerou mais relevantes: em primeiro o álcool conforme tinhamos imaginado, mas depois as 2 variáveis que melhor divide a nota são volatileacidity e novamente o álcool - o que nos leva a pensar que quanto mais álcool o vinho branco tiver, melhor ele deve ser. Em um nível abaixo, podemos ver o álcool novamente, no lado esquerdo, classificando a nota 5 (valor baixo de álcool). Portanto essa variável definitivamente é importante na hora de predizer a qualidade do vinho.  

*****
## Árvore de decisão
*****
A árvore de decisão, diferente da árvore de regressão, precisa classificar - retornar algo categórico. Mas a ideia será a mesma: utilizará todas as variáveis e depois classifica quais são as que melhor categorizam quality.  

A principio será aplicado o modelo de árvore de decisão do jeito que está. Depois de analisar os resultados, vamos modificar o dataset para mudar as notas numéricas para "bom" e "ruim".
```{r warning=FALSE, message=FALSE}
set.seed(20)
arvore_br <- rpart(as.factor(quality) ~ freesulfurdioxide + totalsulfurdioxide + 
    residualsugar + fixedacidity + volatileacidity + citricacid + 
    chlorides + density + pH + sulphates + alcohol, data = trainData)

summary(arvore_br)

rpart.plot(arvore_br)

#probabilidades_br <- predict(arvore_br, newdata = branco, type = 'prob')

pred_ar <- predict(arvore_br, newdata = testData, type = 'class')
testData$arvDec <- pred_ar

head(select(testData, quality, rl, arvReg, arvDec), n = 30)
```

Vale ressaltar que tivemos que transformar o campo "quality" como factor (demos uma classificação a ele), senão ele teria feito uma árvore de regressão. O resultado já foi um pouco diferente diferente da árvore anterior.

A seguir, vamos alterar as notas em 'bom' e 'ruim' - como a maior parte das notas são 6, ruim = (3,4,5) e bom = (7,8,9). O meio será desconsiderado na análise.

```{r warning=FALSE, message=FALSE}
#filtrar o 6 e reclassificar
trainData <- filter(trainData, quality != 6)
testData <- filter(testData, quality != 6)
trainData$quality2 <- cut(trainData$quality, 2, include.lowest=TRUE, labels=c("Ruim", "Bom"))
testData$quality2 <- cut(testData$quality, 2, include.lowest=TRUE, labels=c("Ruim", "Bom"))

#refazer arvore de decisao
set.seed(20)
arvore_br <- rpart(quality2 ~ freesulfurdioxide + totalsulfurdioxide + 
    residualsugar + fixedacidity + volatileacidity + citricacid + 
    chlorides + density + pH + sulphates + alcohol, data = trainData)

summary(arvore_br)

rpart.plot(arvore_br)

#probabilidades_br <- predict(arvore_br, newdata = branco, type = 'prob')

pred_ar <- predict(arvore_br, newdata = testData, type = 'class')
testData$arvDec2 <- pred_ar

head(select(testData, quality, rl, arvDec, arvDec2), n = 30)
```

Novamente observamos as classificações muito parecidas com árvore anterior, antes da classificação binária, com a variável álcool sendo a mais relevante no modelo.

*****
## Regressão logística
*****
Por último, aplicaremos a regressão logística para modelagem, que visa predizer valores por uma variável categórica também a partir de variáveis explicativas contínuas e/ou binárias.

```{r warning=FALSE, message=FALSE}
attach(trainData)
modelo_log<-glm(quality2 ~ freesulfurdioxide + totalsulfurdioxide + 
    residualsugar + fixedacidity + volatileacidity + citricacid + 
    chlorides + density + pH + sulphates + alcohol, data = trainData, family=binomial(link=logit))
summary(modelo_log)

predito<-fitted(modelo_log)

summary(predito)

hist(predito)

fx_predito <- cut(predito, breaks=c(0,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,1), right=F)
plot(fx_predito , trainData$quality2)

attach(testData)
Predito_teste<-predict(modelo_log, testData)

fx_predito1 <- cut(Predito_teste, breaks=c(0,0.50,1), right=F)

MC <- table(testData$quality2,  fx_predito1 , deparse.level = 2) # montar a matriz de confusão  
show(MC) # mostra os resultados  

ACC = sum(diag(MC))/sum(MC) # calcula a acurácia  
show(ACC) # mostra a acurácia  

# Criar variável faixa probabilidade
fx_predito2 <- cut(Predito_teste, breaks=c(0,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,1), right=F)


plot(fx_predito2 , testData$quality2)

# Frequência absoluta
table(fx_predito1,testData$quality2)

# Frequência relativa
prop.table(table(fx_predito1,testData$quality2),2)



fx_predito2 <- cut(Predito_teste, breaks=c(0,0.25,0.50,0.75,1), right=F)

plot(fx_predito2 , testData$quality2)
```

A acurácia da regressão logística foi de 0.54, a mais baixa dos 4 modelos. É possível perceber que o p-value de álcool nesse modelo ficou ruim, enquanto nos outros modelos ele foi mais determinante.  

Em um momento futuro modelos como redes neurais e k-means poderiam ser utilizados para poder fazer análises da variável qualidade. 